---
title: 'PEC 3: Desing & Implementation - Data load, clean-up, transformation & model selection'
author: "UOC - Alumno: Álvaro Rodríguez Sans"
date: "May 2020 - Delivery 23/05/2021"
output:
  html_document:
    toc: yes
    theme: cosmo
    includes:
      in_header: M2.882-TFM-PEC-header.html
    number_sections: yes
    toc_depth: 4
  word_document:
    toc: yes
  pdf_document: 
    fig_caption: yes
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 4
toc-title: "Índex"
bibliography: scholar.bib
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 
Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.
When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).
The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

The bibliographic references used for this practice have been: [@baayen2008analyzing;@hothorn2014handbook;@hyndman;@livpujndanali;@teetor2011r;@vegasndpreprod].

```{r}
if(!require(knitr)){
    install.packages('knitr', repos='http://cran.us.r-project.org')
    library(knitr)}
if(!require(latexpdf)){
    install.packages('latexpdf', repos='http://cran.us.r-project.org')
    library(latexpdf)}
if(!require(latex2exp)){
    install.packages('latex2exp', repos='http://cran.us.r-project.org')
    library(latex2exp)}
if(!require(lubridate)){
    install.packages('lubridate', repos='http://cran.us.r-project.org')
    library(lubridate)}
if(!require(psych)){
    install.packages("psych", repos='http://cran.us.r-project.org')
    library(psych)}
if(!require(DescTools)){
    install.packages("DescTools", repos='http://cran.us.r-project.org')
    library(DescTools)}
if(!require(tidyverse)){
    install.packages("tidyverse", repos='http://cran.us.r-project.org')
    library(tidyverse)}
if(!require(imputeTS)){
    install.packages("imputeTS", repos='http://cran.us.r-project.org')
    library(imputeTS)}
if(!require(stats)){
    install.packages("stats", repos='http://cran.us.r-project.org')
    library(stats)}
if(!require(tsbox)){
    install.packages("tsbox", repos='http://cran.us.r-project.org')
    library(tsbox)}
if(!require(fable)){
    install.packages("fable", repos='http://cran.us.r-project.org')
    library(fable)}
if(!require(fpp3)){
    install.packages("fpp3", repos='http://cran.us.r-project.org')
    library(fpp3)}
if(!require(corrplot)){
    install.packages('corrplot', repos='http://cran.us.r-project.org')
    library(corrplot)}
knitr::opts_chunk$set(echo = TRUE)
```

# Data load

Data is loaded from the sources stated at PEC1 and PEC2 (CNE, INE and Google).

- [CNE-Covid-19](https://cnecovid.isciii.es/covid19/#documentacion-y-datos)
- [INE-Covid-19](https://www.ine.es/jaxiT3/Datos.htm?t=37811#!tabs-grafico)
- [Google-Covid-19](https://www.google.com/covid19/mobility/)

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(dplyr)
# Source INE 
EM3 <- read.csv('EM3-Movimiento de personas por provincias.csv', 
                header=TRUE, 
                sep = ";", 
                stringsAsFactors = FALSE)

# Source Google
Google <- read.csv('Google-2020_ES_Region_Mobility_Report.csv', 
                   header=TRUE, 
                   sep = ";", 
                   stringsAsFactors = FALSE)

# Source CNE
CNE_tecnica <- read.csv('CNE-casos_tecnica_provincia.csv', 
                        header=TRUE, 
                        sep = ",", 
                        stringsAsFactors = FALSE)
CNE_casos <- read.csv('CNE-casos_hosp_uci_def_sexo_edad_provres.csv', 
                      header=TRUE,
                      sep = ",",
                      stringsAsFactors = FALSE)
```

# Initial descriptive statistics and visualization

## Data types and modifications

We are gonig to check the **type of variable** that corresponds to each of the variables (numerical, factor, etc.) and **missing data / values or other anomalies** in each dataset.

### EM3 review

We have the movement of people by provinces (we can see 146 rows by province, that correspond to days). In order to facilitate the comparison and have a valid reference on to what extent the mobility of the population should be considered to have varied, the data of a day of a week that can be considered "normal" are taken as a reference. For this study, the "normal" day that has been considered is the one that results from the average of the days 18 (Monday) to 21 (Thursday) of November 2019. It is indicated in the tables as the reference date 18/11/2019.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Source INE 
head(str(EM3,vec.len=2))
summary(EM3)
table(EM3$Zonas.de.movilidad)
```

### EM3 data transformation

We are going to **transform**:

* "Total" from "character" to "numerical" 
* "Periodo" from "character" to "date"

```{r echo=TRUE, message=FALSE, warning=FALSE}
EM3$Total <- sub(",", ".", EM3$Total)
EM3$Total <- as.numeric(EM3$Total)
EM3$Periodo <- as.Date(EM3$Periodo,format="%d/%m/%Y")
head(EM3)
```

### EM3 transpose

Due to the nature of this dataset we have to transpose it in order to analyse the missing values and impute them.

```{r echo=TRUE, message=FALSE, warning=FALSE}
if(!require(data.table)){
    install.packages('data.table', repos='http://cran.us.r-project.org')
    library(data.table)}

# Transpose dataframe 
EM3_t<-dcast(EM3, Periodo~Zonas.de.movilidad, fill=NA)

# Create dates missing (for time series).
# Note: Acccording INE some dates are not provided.
EM3_t<-EM3_t %>%
  complete(Periodo = seq.Date(min(Periodo), max(Periodo), by="day"))

# Filter the interest period according INE EM3 study
EM3_t<- EM3_t %>% 
  filter(Periodo <= "2019-11-18" | Periodo >= "2020-03-16")

EM3_t
```

### EM3 review missing values & impute

We check the missing values by province (we are close to 150 by province).

```{r echo=TRUE, message=FALSE, warning=FALSE}
if(!require(VIM)){
    install.packages('VIM', repos='http://cran.us.r-project.org')
    library(VIM)}

aggr(EM3_t[,-1], col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(EM3_t[,-1]), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

EM3_t %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We impute the missing values following the principales stated for [imputeTS](https://cran.r-project.org/web/packages/imputeTS/vignettes/imputeTS-Time-Series-Missing-Value-Imputation-in-R.pdf). Thanks to this approach we almost double the amount of data for analysis by province (It was selected "na_seadec" due to it covers seasonality aspects -weekdays/weekends in our case-).

It is needed to transform the dataframe to a time series object.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Used to convert dataframe to ts object
library(xts) 
EM3_t_ts<-xts(EM3_t[-1],EM3_t$Periodo)
 
# Impute the missing values with na_kalman, na_seadec, na_interpolation & na_seasplit 
imp <- na_kalman(EM3_t_ts[,1])
ggplot_na_imputations(EM3_t_ts[,1], imp)

imp2 <- na_seadec(EM3_t_ts[,1])
ggplot_na_imputations(EM3_t_ts[,1], imp2)

imp3 <- na_seasplit(EM3_t_ts[,1])
ggplot_na_imputations(EM3_t_ts[,1], imp3)

imp4 <- na_interpolation(EM3_t_ts[,1])
ggplot_na_imputations(EM3_t_ts[,1], imp4)

# We select na_seadec for the dataset
EM3_t_ts <- na_seadec(EM3_t_ts)
plot(EM3_t_ts[,1])

# We convert the time series object to a dataframe
EM3 <- ts_df(EM3_t_ts)

names(EM3)[names(EM3) == "id"] <- "Zonas.de.movilidad"
names(EM3)[names(EM3) == "time"] <- "Periodo"
names(EM3)[names(EM3) == "value"] <- "Total"

# Transpose dataframe 
EM3_t<-dcast(EM3, Periodo~Zonas.de.movilidad, fill=NA)

# We check again missing values (result should be zero)
aggr(EM3_t[,-1], col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(EM3_t[,-1]), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

EM3_t %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

head(str(EM3,vec.len=2))
summary(EM3)
table(EM3$Zonas.de.movilidad)
```

### Google review

Here we have data from autonomus communities and provinces.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Source Google
head(str(Google,vec.len=1))
summary(Google)
table(Google$sub_region_1)
table(Google$sub_region_2)
table(Google$iso_3166_2_code)
```

### Google autonomous-communities & provinces

We check data grouped by autonomous communities and provinces.

```{r echo=TRUE, message=FALSE, warning=FALSE}
Google %>% group_by(sub_region_1) %>% tally()
Google %>% group_by(sub_region_1) %>% count(sub_region_2)
```

In Spain there are **autonomous communities (AC)** and **autonomous cities (C)** that are considered as **provinces (Pr)**. This is the case for:

* AC - Asturias, Principality - Pr - Asturias
* AC - Balears, Illes - Pr - Balears, Illes
* AC - Cantabria - Pr - Cantabria
* AC - Madrid, Community - Pr - Madrid
* AC - Murcia, Region - Pr- Murcia
* AC - Navarra, Foral Community - Pr - Navarra
* AC - Rioja, La - Pr - Rioja, La
* C - Ceuta - C/Pr - Ceuta
* C - Melilla - C/Pr - Melilla 

In this data set, the empty values in the "sub_region_2" column, for the autonomous communities mentinoed, will be replaced by the value contained in the "sub_region_1" column (A). Also we are going to modify the names of the provinces that have special characters in order to adopt the INE standards (B). See note.

**Note** The following links states the provinces in Spain [INE CCAA](https://www.ine.es/daco/daco42/codmun/cod_ccaa_provincia.htm) and its [ISO codes](https://es.wikipedia.org/wiki/ISO_3166-2:ES) are going to be used as tables of referencence.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Modidication provinces - A
Google$sub_region_2[Google$sub_region_1=="Balearic Islands"] <- "Balears, Illes"
Google$iso_3166_2_code[Google$sub_region_2=="Balears, Illes"] <- "PM"

Google$sub_region_2[Google$sub_region_1=="Asturias"] <- "Asturias"
Google$iso_3166_2_code[Google$sub_region_2=="Asturias"] <- "O"

Google$sub_region_2[Google$sub_region_1=="Cantabria"] <- "Cantabria"
Google$iso_3166_2_code[Google$sub_region_2=="Cantabria"] <- "S"

Google$sub_region_2[Google$sub_region_1=="Community of Madrid"] <- "Madrid"
Google$iso_3166_2_code[Google$sub_region_2=="Madrid"] <- "M"

Google$sub_region_2[Google$sub_region_1=="Region of Murcia"] <- "Murcia"
Google$iso_3166_2_code[Google$sub_region_2=="Murcia"] <- "MU"

Google$sub_region_2[Google$sub_region_1=="Navarre"] <- "Navarra"
Google$iso_3166_2_code[Google$sub_region_2=="Navarra"] <- "NA"

Google$sub_region_2[Google$sub_region_1=="La Rioja"] <- "Rioja, La"
Google$iso_3166_2_code[Google$sub_region_2=="Rioja, La"] <- "LO"

Google$sub_region_2[Google$sub_region_1=="Ceuta"] <- "Ceuta"
Google$iso_3166_2_code[Google$sub_region_2=="Ceuta"] <- "CE"

Google$sub_region_2[Google$sub_region_1=="Melilla"] <- "Melilla"
Google$iso_3166_2_code[Google$sub_region_2=="Melilla"] <- "ML"

# Modidication provinces - B
Google$sub_region_2[Google$sub_region_2=="A CoruÃ±a"]<-"Coruña, A"
Google$sub_region_2[Google$sub_region_2=="Ã\u0081lava"]<-"Araba/Álava"
Google$sub_region_2[Google$sub_region_2=="Ã\u0081vila"]<-"Ávila"
#Google$sub_region_2[Google$sub_region_2=="Albacete"]<-"Albacete"
Google$sub_region_2[Google$sub_region_2=="Alicante"]<-"Alicante/Alacant"
#Google$sub_region_2[Google$sub_region_2=="AlmerÃa"]<-"Almería"
#Google$sub_region_2[Google$sub_region_2=="Asturias"]<-"Asturias"
#Google$sub_region_2[Google$sub_region_2=="Badajoz"]<-"Badajoz"
#Google$sub_region_2[Google$sub_region_2=="Balears, Illes"]<-"Balears, Illes"
#Google$sub_region_2[Google$sub_region_2=="Barcelona"]<-"Barcelona"
Google$sub_region_2[Google$sub_region_2=="Biscay"]<-"Bizkaia"
#Google$sub_region_2[Google$sub_region_2=="Burgos"]<-"Burgos"
Google$sub_region_2[Google$sub_region_2=="CÃ¡ceres"]<-"Cáceres"
Google$sub_region_2[Google$sub_region_2=="CÃ¡diz"]<-"Cádiz"
Google$sub_region_2[Google$sub_region_2=="CÃ³rdoba"]<-"Córdoba"
#Google$sub_region_2[Google$sub_region_2=="Cantabria"]<-"Cantabria"
Google$sub_region_2[Google$sub_region_2=="CastellÃ³n"]<-"Castellón/Castelló"
#Google$sub_region_2[Google$sub_region_2=="Ceuta"]<-"Ceuta"
#Google$sub_region_2[Google$sub_region_2=="Ciudad Real"]<-"Ciudad Real"
#Google$sub_region_2[Google$sub_region_2=="Cuenca"]<-"Cuenca"
#Google$sub_region_2[Google$sub_region_2=="Gipuzkoa"]<-"Gipuzkoa"
#Google$sub_region_2[Google$sub_region_2=="Girona"]<-"Girona"
#Google$sub_region_2[Google$sub_region_2=="Granada"]<-"Granada"
#Google$sub_region_2[Google$sub_region_2=="Guadalajara"]<-"Guadalajara"
#Google$sub_region_2[Google$sub_region_2=="Huelva"]<-"Huelva"
#Google$sub_region_2[Google$sub_region_2=="Huesca"]<-"Huesca"
Google$sub_region_2[Google$sub_region_2=="JaÃ©n"]<-"Jaén"
Google$sub_region_2[Google$sub_region_2=="Las Palmas"]<-"Palmas, Las"
Google$sub_region_2[Google$sub_region_2=="LeÃ³n"]<-"León"
#Google$sub_region_2[Google$sub_region_2=="Lleida"]<-"Lleida"
#Google$sub_region_2[Google$sub_region_2=="Lugo"]<-"Lugo"
Google$sub_region_2[Google$sub_region_2=="MÃ¡laga"]<-"Málaga"
#Google$sub_region_2[Google$sub_region_2=="Madrid"]<-"Madrid"
#Google$sub_region_2[Google$sub_region_2=="Melilla"]<-"Melilla"
#Google$sub_region_2[Google$sub_region_2=="Murcia"]<-"Murcia"
#Google$sub_region_2[Google$sub_region_2=="Navarra"]<-"Navarra"
#Google$sub_region_2[Google$sub_region_2=="Palencia"]<-"Palencia"
#Google$sub_region_2[Google$sub_region_2=="Pontevedra"]<-"Pontevedra"
Google$sub_region_2[Google$sub_region_2=="Province of Ourense"]<-"Ourense"
#Google$sub_region_2[Google$sub_region_2=="Rioja, La"]<-"Rioja, La"
#Google$sub_region_2[Google$sub_region_2=="Salamanca"]<-"Salamanca"
#Google$sub_region_2[Google$sub_region_2=="Santa Cruz de Tenerife"]<-"Santa Cruz de Tenerife"
#Google$sub_region_2[Google$sub_region_2=="Segovia"]<-"Segovia"
Google$sub_region_2[Google$sub_region_2=="Seville"]<-"Sevilla"
#Google$sub_region_2[Google$sub_region_2=="Soria"]<-"Soria"
#Google$sub_region_2[Google$sub_region_2=="Tarragona"]<-"Tarragona"
#Google$sub_region_2[Google$sub_region_2=="Teruel"]<-"Teruel"
#Google$sub_region_2[Google$sub_region_2=="Toledo"]<-"Toledo"
Google$sub_region_2[Google$sub_region_2=="Valencia"]<-"Valencia/València"
#Google$sub_region_2[Google$sub_region_2=="Valladolid"]<-"Valladolid"
#Google$sub_region_2[Google$sub_region_2=="Zamora"]<-"Zamora"
#Google$sub_region_2[Google$sub_region_2=="Zaragoza"]<-"Zaragoza"
Google$sub_region_2 <- with(Google, ifelse(grepl("^Almer", sub_region_2), 
                                                  "Almería", sub_region_2))

table(Google$sub_region_2)
table(Google$iso_3166_2_code)
```

### Google data transformation

We are going to **transform / eliminate**:

* A - Rows with "na" / "" in "sub_region_1" and "sub_region_2" columns are eliminated.
* B - Date column is transformed from "character" to "date".
* C - Some columns are eliminated due to they are not adding value or they contain blanks (country_region_code, country_region, metro_area, census_fips_code, pace_id).
* D - "ES-" is elimianted from "iso_3166_2_code" column.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Transform / eliminate A
Google <- filter(Google, sub_region_1 != "", sub_region_2 != "" )

# Transform / eliminate B
Google$date <- as.Date(Google$date ,format="%d/%m/%Y")

# Transform / eliminate C
Google<-within(Google, rm(country_region_code,
                  country_region,
                  metro_area,
                  census_fips_code,
                  place_id))

# Transform / eliminate D
Google$iso_3166_2_code <- gsub("ES-", "", Google$iso_3166_2_code)

#Google$retail_and_recreation_percent_change_from_baseline <- as.numeric(Google$retail_and_recreation_percent_change_from_baseline)
#Google$grocery_and_pharmacy_percent_change_from_baseline <- as.numeric(Google$grocery_and_pharmacy_percent_change_from_baseline)
#Google$parks_percent_change_from_baseline <- as.numeric(Google$parks_percent_change_from_baseline)
#Google$transit_stations_percent_change_from_baseline <- as.numeric(Google$transit_stations_percent_change_from_baseline)
#Google$workplaces_percent_change_from_baseline <- as.numeric(Google$workplaces_percent_change_from_baseline)
#Google$residential_percent_change_from_baseline <- as.numeric(Google$residential_percent_change_from_baseline)

head(Google,5)
table(Google$sub_region_2)
table(Google$iso_3166_2_code)
#unique(Google$sub_region_2)
#unique(EM3$Zonas.de.movilidad)
```

### Google review missing values & impute

We check missing values.

```{r echo=TRUE, message=FALSE, warning=FALSE}
aggr(Google, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(Google), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

Google %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We generate 6 new dataframes from the 6 features stated in order to imput missing values using the approach "imputeTS". 

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Transpose dataframe 
Google_retail<-Google[c(2,4,5)]
Google_t_retail<-dcast(Google_retail, date~sub_region_2, fill=NA)

# Visualize missing values
aggr(Google_t_retail, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(Google_t_retail), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

Google_t_retail %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Convert dataframe to ts object
Google_t_retail_ts<-xts(Google_t_retail[-1],Google_t_retail$date)
 
# Impute the missing values with na_seadec (i.e Ceuta)
imp5 <- na_seadec(Google_t_retail_ts[,16])
ggplot_na_imputations(Google_t_retail_ts[,16], imp5)

# We select na_seadec for the dataset
Google_t_retail_ts <- na_seadec(Google_t_retail_ts)
plot(Google_t_retail_ts[,16])

# We convert the time series object to a dataframe
Google_retail <- ts_df(Google_t_retail_ts)

names(Google_retail)[names(Google_retail) == "id"] <- "sub_region_2"
names(Google_retail)[names(Google_retail) == "time"] <- "Date"
names(Google_retail)[names(Google_retail) == "value"] <- "retail_and_recreation_percent_change_from_baseline"

###################################################################
# Transpose dataframe 
Google_grocery<-Google[c(2,4,6)]
Google_t_grocery<-dcast(Google_grocery, date~sub_region_2, fill=NA)

# Visualize missing values
aggr(Google_t_grocery, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(Google_t_grocery), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

Google_t_grocery %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Convert dataframe to ts object
Google_t_grocery_ts<-xts(Google_t_grocery[-1],Google_t_grocery$date)
 
# Impute the missing values with na_seadec (i.e Ceuta)
imp6 <- na_seadec(Google_t_grocery_ts[,16])
ggplot_na_imputations(Google_t_grocery_ts[,16], imp6)

# We select na_seadec for the dataset
Google_t_grocery_ts <- na_seadec(Google_t_grocery_ts)
plot(Google_t_grocery_ts[,16])

# We convert the time series object to a dataframe
Google_grocery <- ts_df(Google_t_grocery_ts)

names(Google_grocery)[names(Google_grocery) == "id"] <- "sub_region_2"
names(Google_grocery)[names(Google_grocery) == "time"] <- "Date"
names(Google_grocery)[names(Google_grocery) == "value"] <- "grocery_and_pharmacy_percent_change_from_baseline"

###################################################################
# Transpose dataframe 
Google_parks<-Google[c(2,4,7)]
Google_t_parks<-dcast(Google_parks, date~sub_region_2, fill=NA)

# Visualize missing values
aggr(Google_t_parks, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(Google_t_parks), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

Google_t_parks %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Convert dataframe to ts object
Google_t_parks_ts<-xts(Google_t_parks[-1],Google_t_parks$date)
 
# Impute the missing values with na_seadec (i.e Ceuta)
imp7 <- na_seadec(Google_t_parks_ts[,16])
ggplot_na_imputations(Google_t_parks_ts[,16], imp7)

# We select na_seadec for the dataset
Google_t_parks_ts <- na_seadec(Google_t_parks_ts)
plot(Google_t_parks_ts[,16])

# We convert the time series object to a dataframe
Google_parks <- ts_df(Google_t_parks_ts)

names(Google_parks)[names(Google_parks) == "id"] <- "sub_region_2"
names(Google_parks)[names(Google_parks) == "time"] <- "Date"
names(Google_parks)[names(Google_parks) == "value"] <- "parks_percent_change_from_baseline"

###################################################################
# Transpose dataframe 
Google_transit<-Google[c(2,4,8)]
Google_t_transit<-dcast(Google_transit, date~sub_region_2, fill=NA)

# Visualize missing values
aggr(Google_t_transit, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(Google_t_transit), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

Google_t_transit %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Convert dataframe to ts object
Google_t_transit_ts<-xts(Google_t_transit[-1],Google_t_transit$date)
 
# Impute the missing values with na_seadec (i.e Ceuta)
imp8 <- na_seadec(Google_t_transit_ts[,16])
ggplot_na_imputations(Google_t_transit_ts[,16], imp8)

# We select na_seadec for the dataset
Google_t_transit_ts <- na_seadec(Google_t_transit_ts)
plot(Google_t_transit_ts[,16])

# We convert the time series object to a dataframe
Google_transit <- ts_df(Google_t_transit_ts)

names(Google_transit)[names(Google_transit) == "id"] <- "sub_region_2"
names(Google_transit)[names(Google_transit) == "time"] <- "Date"
names(Google_transit)[names(Google_transit) == "value"] <- "transit_stations_percent_change_from_baseline"

###################################################################
# Transpose dataframe 
Google_workplaces<-Google[c(2,4,9)]
Google_t_workplaces<-dcast(Google_workplaces, date~sub_region_2, fill=NA)

# Visualize missing values
aggr(Google_t_workplaces, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(Google_t_workplaces), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

Google_t_workplaces %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Convert dataframe to ts object
Google_t_workplaces_ts<-xts(Google_t_workplaces[-1],Google_t_workplaces$date)
 
# Impute the missing values with na_seadec (i.e Ceuta)
imp9 <- na_seadec(Google_t_workplaces_ts[,16])
ggplot_na_imputations(Google_t_workplaces_ts[,16], imp9)

# We select na_seadec for the dataset
Google_t_workplaces_ts <- na_seadec(Google_t_workplaces_ts)
plot(Google_t_workplaces_ts[,16])

# We convert the time series object to a dataframe
Google_workplaces <- ts_df(Google_t_workplaces_ts)

names(Google_workplaces)[names(Google_workplaces) == "id"] <- "sub_region_2"
names(Google_workplaces)[names(Google_workplaces) == "time"] <- "Date"
names(Google_workplaces)[names(Google_workplaces) == "value"] <- "workplaces_percent_change_from_baseline"

###################################################################
# Transpose dataframe 
Google_residential<-Google[c(2,4,10)]
Google_t_residential<-dcast(Google_residential, date~sub_region_2, fill=NA)

# Visualize missing values
aggr(Google_t_residential, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(Google_t_residential), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

Google_t_residential %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Convert dataframe to ts object
Google_t_residential_ts<-xts(Google_t_residential[-1],Google_t_residential$date)
 
# Impute the missing values with na_seadec (i.e Ceuta)
imp10 <- na_seadec(Google_t_residential_ts[,16])
ggplot_na_imputations(Google_t_residential_ts[,16], imp10)

# We select na_seadec for the dataset
Google_t_residential_ts <- na_seadec(Google_t_residential_ts)
plot(Google_t_residential_ts[,16])

# We convert the time series object to a dataframe
Google_residential <- ts_df(Google_t_residential_ts)

names(Google_residential)[names(Google_residential) == "id"] <- "sub_region_2"
names(Google_residential)[names(Google_residential) == "time"] <- "Date"
names(Google_residential)[names(Google_residential) == "value"] <- "residential_percent_change_from_baseline"
```

Now we merge the previous dataframes into new one with the imputed vaules and we add the ISO code for the province.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# New dataframe Google_b 
Google_b <- merge(Google_retail, Google_grocery) %>%
              merge(Google_parks) %>%
              merge(Google_transit) %>%
              merge(Google_workplaces) %>%
              merge(Google_residential) 

Google_b$iso_code <- NA
Google_b$iso_code<-Google[match(Google_b$sub_region_2, Google$sub_region_2),3]
rm("Google")
Google<-Google_b
rm("Google_b")
head(Google,5)
table(Google$sub_region_2)
table(Google$iso_code)
```

We check missing values. We should obtain zero missing values.

```{r echo=TRUE, message=FALSE, warning=FALSE}
aggr(Google, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(Google), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

Google %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### CNE review

The CSV files are provided per "imputed date" (fecha)":

* **cases_technic_province.csv** - Number of cases by diagnostic technique and province (of residence)
* **cases_hosp_uci_def_sexo_edad_provres.csv** - Number of hospitalizations, number of ICU admissions and number of deaths by sex, age and province of residence.

```{r echo=TRUE, message=FALSE, warning=FALSE}
head(str(CNE_tecnica, vec.len=3))
summary(CNE_tecnica)
table(CNE_tecnica$provincia_iso)
```

### CNE review missing values & impute

We check missing values for CNE_tecnica. In this case we omit the NA values.

```{r echo=TRUE, message=FALSE, warning=FALSE}
aggr(CNE_tecnica, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(CNE_tecnica), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

CNE_tecnica %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

####################################
CNE_tecnica <- na.omit(CNE_tecnica)
####################################

aggr(CNE_tecnica, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(CNE_tecnica), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

CNE_tecnica %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
head(str(CNE_casos,vec.len=3))
summary(CNE_casos)
table(CNE_casos$provincia_iso)
```

We check missing values for CNE_casos. In this case also we omit the NA values.

```{r echo=TRUE, message=FALSE, warning=FALSE}
aggr(CNE_casos, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(CNE_casos), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

CNE_casos %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

###############################
CNE_casos <- na.omit(CNE_casos)
###############################

aggr(CNE_casos, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(CNE_casos), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

CNE_casos %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### CNE data transformation

We are going to **transform / eliminate**:

* A - "Fecha" column is transformed (in both datasets) from "character" to "date".
* B - "Grupo_edad" and "Sexo" columns are eliminated from dataset "CNE_casos" due to they are not adding value (mobility does not include this variable).
* C - We change NC iso code to NA (Navarra) in both dataframes.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Transform / eliminate A
CNE_tecnica$fecha <- as.Date(CNE_tecnica$fecha ,format="%Y-%m-%d")
CNE_casos$fecha <- as.Date(CNE_casos$fecha ,format="%Y-%m-%d")

# Transform / eliminate B
CNE_casos<-within(CNE_casos, rm(grupo_edad, sexo))

# Iso code update for Navarra C
CNE_tecnica$provincia_iso[CNE_tecnica$provincia_iso=="NC"] <- "NA"
CNE_casos$provincia_iso[CNE_casos$provincia_iso=="NC"] <- "NA"

head(CNE_tecnica,5)
head(CNE_casos,5)
```

We check both dataframes offers the same total results.

```{r echo=TRUE, message=FALSE, warning=FALSE}
CNE_tecnica %>% 
  group_by(provincia_iso) %>% 
  summarise_at(vars(num_casos), sum)

CNE_casos %>% 
  group_by(provincia_iso) %>% 
  summarise_at(vars(num_casos), sum)
```

## Datasets combinations

We proceed to **combine** the different data sets into one.

### CNE_tec_cas

* CNE_casos_g, a groupped dataframe due to the columns eliminated in previous step (grupo_edad, sexo)
* CNE_tec_cas -> CNE_tecnica + CNE_casos_g

Here we merge by columns "provincia_iso","fecha".

```{r echo=TRUE, message=FALSE, warning=FALSE}
# CNE_casos_g 
CNE_casos_g = CNE_casos %>% 
  group_by(provincia_iso, fecha) %>% 
  summarise_at(vars(num_casos, num_hosp, num_uci, num_def), sum)
head(CNE_casos_g,5)

# New dataframe CNE_tec_cas 
CNE_tec_cas<-merge(CNE_tecnica, 
                   CNE_casos_g, by.x=c("provincia_iso","fecha"), 
                   by.y=c("provincia_iso","fecha")) 

# We check both dataframes offers the same total results
CNE_tecnica %>% 
  group_by(provincia_iso) %>% 
  summarise_at(vars(num_casos), sum)
CNE_casos_g %>% 
  group_by(provincia_iso) %>% 
  summarise_at(vars(num_casos), sum)

head(CNE_tec_cas,5)
table(CNE_tec_cas$provincia_iso)
```

### GOG_CNE

* GOG_CNE -> CNE_tec_cas + Google

Here we merge by columns "provincia_iso" / "fecha" and "iso_3166_2_code" / "date".

```{r echo=TRUE, message=FALSE, warning=FALSE}
# New dataframe GOG_CNE 
GOG_CNE<-merge(CNE_tec_cas, 
               Google, 
               by.x=c("provincia_iso","fecha"), 
               by.y=c("iso_code","Date"))
head(GOG_CNE,5)
table(GOG_CNE$provincia_iso)
```

### Total

* Total -> GOG_CNE + EM3

Here we merge by columns "sub_region_2" / "fecha" and "Zonas.de.movilidad" / "Periodo".
With this dataset we have 21 features for study.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# New dataframe Total 
Total<-merge(GOG_CNE, 
             EM3, 
             by.x=c("sub_region_2","fecha"), 
             by.y=c("Zonas.de.movilidad","Periodo")) 
head(Total,5)
head(str(Total,vec.len=1))
summary(Total)
table(Total$sub_region_2)
table(Total$provincia_iso)
```

We check the missing values. We should have zero missing values

```{r echo=TRUE, message=FALSE, warning=FALSE}
aggr(Total, col=c('navyblue','yellow'),
     numbers=TRUE, sortVars=TRUE,
     labels=names(Total), cex.axis=.7,
     gap=3, ylab=c("Missing data","Pattern"))

Total %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) %>%
    ggplot() +
    geom_bar(aes(x=key, y=num.missing), stat = 'identity',fill="#F0E442") +
    labs(x='variable', y="number of missing values", 
         title='Number of missing values') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Review results 
# Discrepancies due to different time-frames when merge CNE dataframes (see previous checks)
Total %>% 
  group_by(provincia_iso) %>% 
  summarise_at(vars(num_casos.x,num_casos.y), sum)

# CSV file generation
head(Total,5)
write.csv2(Total,"D:\\UOC Master Data Science\\_ M2.882 - TFM - Área 5\\UOC - Guia - PECS\\Pec3\\Total.csv", row.names = FALSE)
```

## Visual analysis

### Dataframe plots 

We have generated some plots from the **dataframe** object generated.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Line plots
# All num_casos.x
ggplot(Total, aes(x=fecha, y=num_casos.x, group=sub_region_2)) +
  geom_line(aes(linetype=sub_region_2, color=sub_region_2))+
  geom_point(aes(color=sub_region_2))+
  theme(legend.position="top") +
  labs(title="Cases by Province",
        x ="Date", y = "Nº of cases")

# All Total (mobility)
ggplot(Total, aes(x=fecha, y=Total, group=sub_region_2)) +
  geom_line(aes(linetype=sub_region_2, color=sub_region_2))+
  geom_point(aes(color=sub_region_2))+
  theme(legend.position="top") +
  labs(title="Mobility Change by Province",
        x ="Date", y = "% Mobility")

# Mal, Cor and Cad - num_casos.x
Total %>%
  filter(sub_region_2 == "Málaga" | sub_region_2 == "Cádiz" |
         sub_region_2 == "Córdoba") %>%
  ggplot(aes(x=fecha, y=num_casos.x))+
    geom_line(aes(color=sub_region_2))+
    geom_point(aes(color=sub_region_2))+
    theme(legend.position="top") +
    labs(title="Cases by Province (Málaga, Córdoba and Cádiz)",
        x ="Date", y = "Nº of cases")

# Mal, Cor and Cad - Total (mobility)
Total %>%
  filter(sub_region_2 == "Málaga" | sub_region_2 == "Cádiz" |
         sub_region_2 == "Córdoba") %>%
  ggplot(aes(x=fecha, y=Total))+
    geom_line(aes(color=sub_region_2))+
    geom_point(aes(color=sub_region_2))+
    theme(legend.position="top") +
  labs(title="Mobility Change by Province (Málaga, Córdoba and Cádiz)",
        x ="Date", y = "% Mobility")
```

### Time-series plots

We have generated some plots from the **time-series** object generated.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Convert dataframe to ts object
Total_ts <- Total[-3] %>% 
  mutate(Dia_c = as_date(fecha)) %>%
  select(-fecha) %>%
  as_tsibble(key = c(sub_region_2),
             index = Dia_c)

# Filter for Bar, Mad, Mal, Cor and, Cad
Total_ts %>% filter(sub_region_2 == "Barcelona" | sub_region_2 == "Madrid" | 
                    sub_region_2 == "Málaga" | sub_region_2 == "Sevilla" | 
                    sub_region_2 == "Córdoba") -> Total_ts_b

# Plots
# A num_casos.x,num_casos.y
autoplot(Total_ts_b, vars(num_casos.x,num_casos.y)) + 
  labs(y = "Nº of Cases",
       title = "Reported Cases (CNE A vs B)")
 
# B Total (mobility)
autoplot(Total_ts_b, Total) +
  facet_wrap(~sub_region_2, scales = "free_y", ncol=2) + 
  theme(legend.position = "top") + 
  scale_x_date(date_minor_breaks = "1 day", name = "Time (Daily)") + 
  ggtitle(label = "Mobility Change by Province (Málaga, Córdoba and Cádiz)")

# C sub_region_2 == "Barcelona" by month
Total_ts %>% filter(sub_region_2 == "Barcelona") %>%
  gg_season(num_casos.x, period = "month", labels = "both") +
  theme(legend.position = "top") +
  labs(y="Nº of Cases", title="Barcelona - Infections by Month")
```

### Correlation plots

```{r echo=TRUE, message=FALSE, warning=FALSE}
Total.res<-Total %>% 
  filter(sub_region_2 == "Barcelona")
Total.res<-cor(Total.res[,c(-1,-2,-3)],method="spearman")
corrplot.mixed(Total.res,upper="circle",number.cex=.65,tl.cex=.6)
```

### PCA

```{r echo=TRUE, message=FALSE, warning=FALSE}
pca <- prcomp(Total.res, scale = T)
summary(pca)
pca$rotation
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
if(!require(FactoMineR)){
    install.packages('FactoMineR', repos='http://cran.us.r-project.org')
    library(FactoMineR)}
if(!require(factoextra)){
    install.packages('factoextra', repos='http://cran.us.r-project.org')
    library(factoextra)}

# Var contribution for PC1-PC5
fviz_contrib(pca, choice = "var", axes = 1)
fviz_contrib(pca, choice = "var", axes = 2)
fviz_contrib(pca, choice = "var", axes = 3)
fviz_contrib(pca, choice = "var", axes = 4)
fviz_contrib(pca, choice = "var", axes = 5)
```


# Seasonal and trend decomposition

## STL (Seasonal and Trend decomposition using Loess)

As stated by [@hyndman]... "STL has several advantages over classical decomposition, and the SEATS and X-11 methods:

* Unlike SEATS and X-11, STL will handle any type of seasonality, not only monthly and quarterly data.
* The seasonal component is allowed to change over time, and the rate of change can be controlled by the user.
* The smoothness of the trend-cycle can also be controlled by the user.
* It can be robust to outliers (i.e., the user can specify a robust decomposition), so that occasional unusual observations will not affect the estimates of the trend-cycle and seasonal components. They will, however, affect the remainder component"...

```{r echo=TRUE, message=FALSE, warning=FALSE}
dcmp <- Total_ts %>% 
  filter(sub_region_2 == "Barcelona") %>% 
  model(STL(num_casos.x)) 

components(dcmp) %>% autoplot()

components(dcmp) %>%
  as_tsibble() %>%
  autoplot(num_casos.x, color="gray") +
  geom_line(aes(y=trend), color = "#D55E00") 
  
components(dcmp) %>%
  as_tsibble() %>%
  autoplot(num_casos.x, color="gray") +
  geom_line(aes(y=season_adjust), color = "#D55E00") 

#############################
Total_ts %>% 
  filter(sub_region_2 == "Barcelona") %>% 
  model(STL(num_casos.x)) %>%
  components() %>% 
  autoplot()

Total_ts %>% 
  filter(sub_region_2 == "Barcelona") %>% 
  model(STL(num_casos.x ~ season(window = 7) +
              trend(window = 7))) %>%
  components() %>% 
  autoplot()
```

## Till here 06-Apr-2021

# Bibliography
